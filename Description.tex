 \documentclass[12pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}       

\pagestyle{headings}

\usepackage[russian, english]{babel}
\usepackage{amsmath,amsfonts,amsthm,amssymb,amsbsy,amstext,amscd,amsxtra,multicol}
\usepackage{verbatim}
\usepackage{tikz}
\usetikzlibrary{automata,positioning}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage[colorlinks,urlcolor=blue]{hyperref}
\usepackage[stable]{footmisc}
\usepackage{ dsfont }
\usepackage{wrapfig}
\usepackage{xparse}
\usepackage{ifthen}
\usepackage{bm}
\usepackage{color}
 \usepackage{subfigure}
 
\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{xcolor}
\usepackage{hyperref}
\definecolor{linkcolor}{HTML}{799B03} % цвет гиперссылок
\definecolor{urlcolor}{HTML}{799B03} % цвет гиперссылок
 
%\hypersetup{pdfstartview=FitH,  linkcolor=linkcolor,urlcolor=urlcolor, colorlinks=true}

\newtheorem{theorem}{Теорема}[section]
\newtheorem{lemma}{Лемма}[section]
\newtheorem{defin}{Определение}[section]

\title{Когнитивный ассистент}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\intt}{int}
\DeclareMathOperator{\conv}{conv}
\begin{document}

\maketitle

\section{Описание задачи}

В данной работе мы описываем методику конструирования целеориентированного режима когнитивного ассистента (далее КА). Нас интересует построение интерактивной диалоговой системы, т.е. системы, способной анализировать запросы пользователя, задавать ему вопросы и правильно на них отвечать, которая помогает пользователю в построении его собственного плана достижения заранее (в самом начале диалога) обозначенной цели. А именно, цель пользователя является достаточно конкретной (напр., купить автомобиль), и КА должен в процессе диалога максимально конкретизировать цель (в случае автомобиля данной конкретезацией может быть выбор между отечественным автомобилем и иномаркой, между подержанным и новым и т.д.) и провести пользователя по всем этапам достижения цели давая рекомендации.

Мотивацией для создания новой модели поведения когнитивного ассистента является следующее. На данный момент диалоговые системы не показывают результатов, сравнимых с результатом общения с экспертом. Во-первых, текущие технологии не заточены на интерактивное общение с пользователем. А именно, существуют неплохие вопросно ответные системы \cite{1} и есть результаты в создании диалоговых систем для общения на свободную тему (chit-chat) \cite{2}, однако практически не разработаны системы, задающие вопрос пользователю и обрабатывающие ответ для достижения собственных целей. Во-вторых, существующие диалоговые системы плохо заточены для работы в предметной области. Для решения этих задвч в частности используются базы знаний \cite{3}.

\section{Модель ассистента}

\begin{defin} {\textbf{Графом когнитивного ассистента} называется ориентированный граф $G=(V,E),$ такой что выполнены следующие условия:

1. Есть две вершины $s$ и $t$, такие что $d_\text{in}(s)=d_\text{out}(t)=0,$ т.е. в $s$ не входит не одного ребра, из  $t$ не выходит. Эти вершины называются стартовая и терминальная соответсвенно.

2. Каждой вершине $v\in V$ соответствует набор алгоритмов $(\mathcal{M}_v, \mathcal{G}_v, \mathcal{R}_v, \mathcal{I}_v, \mathcal{S}_v)$. Алгоритм $\mathcal{M}_v$  есть \textbf{главный алгоритм}, алгоритм $\mathcal{G}_v$  есть \textbf{алгоритм генерации сообщения}, алгоритм $\mathcal{R}_v$  есть \textbf{алгоритм обработки запроса}, алгоритм $\mathcal{I}_v$  есть \textbf{алгоритм интерактивного общения}, алгоритм $\mathcal{S}_v$  есть textbf{алгоритм принятия решения}. Формальное описание будет дано ниже.}\end{defin}

Главный алгоритм $\mathcal{M}_v$ определяет порядок запуска остальных четырех алгоритмов.

Алгоритм генерации сообщения $\mathcal{G}_v$ есть алгоритм, который выводит единственное сообщение $s$ пользователю. Это сообщение есть полезная информация, которую получит пользователь, в частности, этот алгоритм сообщит, что нужно сделать пользователю для достижения своей цели.

Алгоритм обработки запроса $\mathcal{R}_v$ есть алгоритм, который получает на вход сообщение пользователя, обрабатывает его и, если обнаруживает некоторый запрос, то начинает его обработку. Считается, что все возможные обрабатываемые запросы обработаны заранее и их конечное число. Наиболее важным запросом является запрос на аргументацию одного из ранее полученных сообщений, т.е. запрос на генерацию $a$, который убедит, что одно информация в полученном ранее сообщении поможет пользователю в достижении цели.

Алгоритм принятия решения $\mathcal{S}_v$ есть алгоритм, который используя алгоритм $\mathcal{I}_v$ и всю ранее полученную информацию, принимает решение по какому ребру пойти.

Алгоритм интерактивного общения $\mathcal{I}_v$ есть алгоритм, принимающий на вход три набора сообщений $(\{s_k^1\}, \{s_k^2\}, \{s_k^3\})$ - набор сообщений (или информации, извлеченных из них), полученных от пользователя в пройденных вершинах, набор сообщений (или информации, извлеченных из них), полученных от пользователя в текущей вершине, и набор сообщений, которые характеризуют текущие потребности когнитивного ассистента. Данный алгоритм будет вызываться в $\mathcal{S}_v$ для пополнения информации о пользователе до такого уровня, что можно будет выбрать наилучшую для данного пользователя следующую вершину.

Существует четыре различных случая вершин и соответсвующих им алгоритмов:

1. Конечная вершина

2. Вершина с одним исходящим ребром

3. Вершина с более чем одним исходящим ребром

4. Стартовая вершина

Мы считаем, что если пользователь дошел до конечной вершины $t$, то он достиг своей цели. Поэтому в конечной вершине алгоритмы имеют простую структуру. А именно, $\mathcal{M}_t$ вызывает функцию $\mathcal{G}_t,$ которая выводит некоторое прощальное сообщение и завершает работу. Остальные алгоритмы можно считать алгоритмами, которые завершают свою работу на любом входе за первый шаг, возвращая пустую строку (далее такие алгоритмы будем называть пустыми алгоритмами).

В случае вершины с одним исходящим ребром алгоритм $\mathcal{M}_v$ устроен следующим образом. Во-первых, он выводит сообщение при помощи $\mathcal{G}_v$. Затем вызывает алгоритм $\mathcal{S}_v$, который возвращает единственный возможный вариант. Алгоритм $\mathcal{I}_v$ есть пустой алгоритм. Алгоритм $\mathcal{R}_v$ в этом и в оставшихся случаях мы обсудим позже.

Алгоритм $\mathcal{M}_v$ в оставшихся пунктах устроен следующим образом. Сначала вызывается алгоритм $\mathcal{S}_v$, затем на основе принятого решения генерируется сообщение алгоритмом $\mathcal{G}_v$. Как принимается решение в $\mathcal{S}_v$ и как происходит общение через $\mathcal{I}_v$ мы обсудим после формализации пользователя.

\section{Модель пользователя}

\begin{defin}
Пусть $v$ - вершина, из которой выходит более одного ребра. Пусть $\Omega_v = \{z|(v,z)\in E\}$. Тогда $\Omega_v$ есть \textbf{множество решений}. Также считаем, что каждому элементу этого множества соответсвует 

1. некоторый набор признаков $\textbf{x}_v \in X_v$

2. функция соответсвия $g_v:X_v\times F \rightarrow R_+$, где $F$ - особенности пользователя (см. опреление \ref{user_def}).
\end{defin}

Без ограничения общности здесь и далее мы будем считать, что $X_v \subset \mathbb{R}^n$. Действительно, какими бы не были признаки (бинарные, категориальные и т.д.) существуют способы приведения их к такому виду.

\begin{defin}
\label{user_def}
\textbf{Моделью пользователя} мы будем называть тройку $u = (x_-, x_+, f)$, где

1. $\textbf{x}_-, \textbf{x}_+\in \mathbb{R}^N, N={\sum\limits_{v:d_{out}(v)>1} \dim X_v}$ - некоторые ограничения, которые пользователь ставит на варианты решений для $\Omega_v$, т.е. пользователь хочет, чтобы $\textbf{x}_-|_v \leq \textbf{x}_v^* \leq \textbf{x}_+|_v$. Здесь $\textbf{x}_v^*$ - решение, которое КА примет в вершине $v$, $\textbf{x}_\pm|_v$ - та часть вектора $\textbf{x}_\pm$, которая соответсвует вершине $v$.

2. $\textbf{f}\in F$ - некоторые особенности пользователя.
\end{defin}

Сделаем несколько пояснений к этому определению.

Во-первых, пользователь может не знать, что означает $k$-ый признак варианта в вершине $v$ или он ему может быть не интересен. В обоих этих случаях мы будем считать $x_\pm|_v^k = \pm\infty$.

Во-вторых, обсудим особенности пользователя $F$. Это некоторые характеристики пользователя, которые не связаны явно с характеристиками решений, однако можно установить связь, насколько решение соответствует этим характеристикам при помощи функции соответсвия $g_v$. Примерами таких характеристик могут быть следующие:

1. В случае если КА помогает купить пользователю некоторый предмет, то таковой характеристикой может быть то, зачем пользователю этот предмет.

2. В случае если покупка нуждается в регулярном обслуживании, которое стоит денег, то таковой характетристикой может быть заработок пользователя и/или сколько он готов тратить на это. 

Заметим, что изначально КА не знает $\textbf{u}$, и он может узнать его компоненты или получить оценку на них, используя алгоритм $\mathcal{I}_v$. Однако далее мы будем требовать, чтобы алгоритм не пытался узнать весь вектор $\textbf{u}$, когда это необходимо. Это позволит уменьшить количество запросов к пользователю, а, следовательно, КА станет удобнее для использования.

Далее мы также будем считать, что $F \subset \mathbb{R}_+^d$.

\section{Алгоритм принятия решения}

Целью данного раздела является описание модели принятия решения. Рассмотрим некоторую вершину $v$ со степенью $d_\text{out}(v)>1$. Пусть $X_v$ - множество признаков решений в этой вершине, $g_v:X_v\times F \rightarrow R_+$ - функция соответсвия.

\subsection{Постановка задачи оптимизации}

КА общается с пользователем с параметрами $\textbf{u}=(\textbf{x}_-, \textbf{x}_+, \textbf{f}) \in U$. Определим $\textbf{u}|_v = (\textbf{x}_-|_v, \textbf{x}_+|_v, \textbf{f}) \in U|_v$, т.е. отбросим все признаки, которые не влияют на принятие решения в данной вершине. В данном разделе, мы везде будем использовать $\textbf{u}|_v$, 

Мы будем считать, что КА всегда узнает первыми запросами ограничения, требуемые пользователем, $(\textbf{x}_-, \textbf{x}_+)$. Если пользователю понадобилась помощь КА, то весьма вероятно, что он не имеет достаточно много информации об этих значениях. Поэтому можно считать, что этот ответ не потребует от него много сил.

Определим целевую функцию $s_v:X_v \times U|_v\rightarrow \mathbb{R}$:
\begin{equation}
\label{s_v}
s_{v,\textbf{u}}(\textbf{x}) = g_v(\textbf{x}, \textbf{f}) + \sum\limits_{k=1}^n\lambda_k^- L(\textbf{x}_-|_v^k, x_k) + \sum\limits_{k=1}^n\lambda_k^+ G(\textbf{x}_+|_v^k, x_k),
\end{equation}
где константы $\lambda_k^\pm \geq 0$, функции $L$ и $G$ есть барьерные функции, которые штрафуют за нарушение ограничений. Примерами таких функций могут быть индикаторные функции или их сглаженные аналоги.

Получается , что есть пользователь, с которым общается КА, и у этого пользователя есть некоторый вектор $\textbf{u}$. КА, находясь в вершине $v$, может не знать ничего о векторе $\textbf{u}$, однако, общаясь с пользователем при помощи алгоритма $\mathcal{I}_v$, может узнавать эти признаки. В таком случае, задача алгоритма $\mathcal{S}_v$ найти максимальное или близкое к нему значение функии $s_{v,\textbf{u}}(\textbf{x}) = s_v(\textbf{x}, \textbf{u})$ при фиксированном $u$ на множестве $\{x_z|z \in \Omega_v\}$ при минимальном вызове алгоритма общения $\mathcal{I}_v$.

Задача максимизации $s_v$ при заданном $v$ является задачей дискретной оптимизации и в общем случае, как известно, является $\mathcal{NP}$-трудной. При "небольшом" размере множества вариантов $\Omega_v$ мы можем решать эту задачу при любом $v$ перебором за разумное время. Случай, когда это не выполняется, будет рассмотрен в разделе \ref{complex}. Далее мы будем считать, что есть эффективный метод, который решает задачу:

\begin{equation}
s_{v,\textbf{u}}(\textbf{x})\rightarrow \max\limits_{\textbf{x}\in \{\textbf{x}|z\in \Omega_v\}}.
\end{equation}

Заметим, что в общем случае мы не можем решить эту задачу, не зная значения $\textbf{u}$. Примеры функций, при которых это возможно, а также метод оптимального задавания вопросов будут приведены ниже.

\subsection{Алгоритм интерактивного общения}

В данной секции мы хотим разработать метод генерирования запросов к пользователю, такой что количество этих запросов для уверенного нахождения наилучшего решения $z$ из множества $\Omega_v$ было минимально.

\begin{defin}
\textbf{Множество состояний системы} мы назовем следующий элемент $$\mathsf{P}=\left\{\textbf{x}\Big| x_k \in F_n\cup\{\bot\}\right\}\cup\{\mathbf{p_f}\},$$
где  $\mathbf{p_f}$ некоторый объект не из множества $\left\{\textbf{x}\Big| x_k \in F_n\cup\{\bot\}\right\}$.
Элемент этого множества назовем состоянием системы $\mathbf{p}$.
\end{defin}

Определим далее:
$$F(\textbf{p}) = \{\textbf{f}\in F\Big| f_k = p_k \bigvee p_k=\bot\},$$
т.е. множество всех элементов $F$, значения компонент которых совпадает с известными компонентами $\textbf{p}$.

Теперь пусть у нас имеется некоторая функция информативности $H$ состояния $\mathsf{p}$. Эта функция зависит от выбранной модели $s_{v, \textbf{u}}$. Определим функцию информативности $H:\mathsf{P}\rightarrow \mathbb{R}$. Для этого нам понадобятся вспомогательные функии:
$$M(\textbf{p}, z) = \max\limits_{\textbf{u}\in\{\textbf{u}|\textbf{f}\in F(\textbf{p})\}}s_{v,\textbf{u}}(\textbf{x}_z), z \in \Omega_v$$
$$m(\textbf{p}, z) = \min\limits_{\textbf{u}\in\{\textbf{u}|\textbf{f}\in F(\textbf{p})\}}s_{v,\textbf{u}}(\textbf{x}_z), z \in \Omega_v$$

В силу того, что мы хотим решить задачу максимизации \ref{s_v}, то критерием информативности будет то, насколько уверенно мы можем сказать, что максимум этой функции при не полностью определенном $\textbf{u}$ близок к максимуму при полностью определенном. Поэтому функция $H$ зависит от модели выбора решения. Рассмотрим несколько вариантов:

1. Минимаксный подход. $z_1=\arg\max_{z\in \Omega_v} m(p,z)$ (в случае, если таких значений несколько, то выберем с максимальным значением $M(p,z)$). В таком случае, функцией информативности будет являться: $$H(p)=m(p,z_1)-\max_{z\in \Omega_v\backslash{z_1}}M(p,z),$$
т.е. функция информативности показывает, насколько значение целевого функционала могло бы увеличиться, если бы уточнить информацию.

2. Вероятностный подход. Если ввести вероятностное пространство относительно множества элементарных исходов $F(\textbf{p})$ и предположить, что многомерная случайная величина $\|s_{v, \textbf{u}}(z)\|_{z_k}$ имеет известное распределение $f$ на $[m(\textbf{p},z), M(\textbf{p},z)]$, то можно использовать вероятностные соображения для определения функции информативности. Пусть $z_1$ есть элемент из $\Omega_v$, с максимальным матожиданием и минимальным размером носителя распределения. Пусть $z_2$ есть элемент из $\Omega_v\backslash \{z_1\}$, выбранный по тем же правилам. Введем обозначения, $m_k = m(\textbf{p}, z_k), M_k = M(\textbf{p}, z_k)$ и определим функцию информативности как, то что $z_1$ оптимальнее $z_2$ не менее, чем на $\epsilon$ по значению функции:
$$H(\textbf{p})=\mathbb{P}\left(s_{v, \textbf{u}}(z_2) < s_{v, \textbf{u}}(z_1) + \epsilon\right)$$
$$H(\textbf{p})=\int\limits_{\max(m_1, m_2-\epsilon)}^{M_1}ds_1 \int\limits_{m_2}^{\min(M_2, s_1+\epsilon)}f_{z_1, z_2}(s_1, s_2) ds_2$$
В частности, для равномерного распределения получаем:
$$\dots$$

Также определим функцию штрафа $\gamma$ за то, что  для состояния $\mathbf{p}$. Эта функция должна выражать наше желание получить информацию за минимальное количество запросов. В таком случае можно считать, что у нас задана функция $\gamma(|\mathbf{p}|)$, не убывающая с ростом $\textbf{p}$. Тогда награждение для состояния $\mathbf{p}$ мы определим, как
$$r(\mathbf{p}) = H(\mathbf{p}) - \gamma(|\mathbf{p}|)$$
$$r(\mathbf{p}_f) = 0$$
Также введем множество действий $A=\{a_j|j=\overline{1,\dim F}\}\cup\{a_f\}$. Действие $a_f$ переводит любое состояние $\mathbf{p}$ в финальное состояние $\mathbf{p}_f$ и далее он не будет обсуждаться. Каждый элемент этого множества позволяет перейти из состояния $\mathbf{p}$ в одно состояние из множества

\begin{equation}
a_j(\mathbf{p})=
\begin{cases}
\left\{\mathbf{p}'\Big|\mathbf{p}\backslash \mathbf{p}' = (j, y)\right\} \text{, если $(j,y) \notin \mathbf{p}, \forall y$} \\
\text{пустое множество, иначе.}
\end{cases}
\end{equation}

Введем также модель переходов между состояниями:
\begin{equation}
T(\mathbf{p}, a, \mathbf{p}') = 
\begin{cases}
0\text{, если $\mathbb{P}(a(\mathbf{p}) = \mathbf{p}') = 0$}\\
f(\mathbf{p}'|\mathbf{p})\text{, иначе}
\end{cases}
\end{equation}
Теперь мы можем сформлурировать задачу обучения с подкреплением. Нашей моделью будет $(\mathsf{P}, p_0, A, T, R),$ где $p_0 = \|\bot\|_k$. При этом любое состояние может быть как финитным, так и не финитным.

Заметим, что множество $\mathbf{F}$, а, следовательно, и множество состояний $S$ не обязаны быть конечными. В то же время множество действий $A$ в сформулированной задаче всегда конечно, и $|A|=\dim F$.

\subsection{Ограничения вычислительной мощности}
\label{complex}
$\dots$

\subsection{Целевая функция}
\label{obj_func}


$\dots$

\section{Оценка качества}

$\dots$


\section{КА для задачи покупки автомобиля}

$\dots$

\section{Заключение}

$\dots$


\end{document}
